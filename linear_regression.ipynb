{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "86665cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "37373a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset and extracting independent and dependdent variables\n",
    "companies = pd.read_csv('1000_Companies.csv')\n",
    "# 'X' is others factors (excluding profit)\n",
    "X = companies.iloc[: , :-1].values\n",
    "# 'Y' is profit\n",
    "Y = companies.iloc[:,4].values\n",
    "# companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1952b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "# Building the Correlation matrix\n",
    "# sns.heatmap(companies.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2e0ce882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder = LabelEncoder()\n",
    "X[ : , 3] = labelencoder.fit_transform(X[ : , 3])\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(), [3])],    \n",
    "    remainder='passthrough'                      \n",
    ")\n",
    "# onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "# X = onehotencoder.fit_transform(X).toarray()\n",
    "X = np.array(ct.fit_transform(X), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7f79dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c7efbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2 , random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3dbd3570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "41de62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "Y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4d21d26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.80536598e+02, -6.98169073e+02,  5.25845857e-01,  8.44390881e-01,\n",
       "        1.07574255e-01])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3e947541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-51035.22972401607"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ef316be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9345303042487786"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if r2 score is > 0.91** then model is good\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d88ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
